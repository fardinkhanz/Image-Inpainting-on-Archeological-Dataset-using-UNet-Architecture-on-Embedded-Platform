{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n","from tensorflow.python.keras.utils import conv_utils\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm\n","import pickle\n","\n","\n","from random import randint, seed\n","import itertools\n","import cv2"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:28:20.120972Z","iopub.execute_input":"2021-12-27T00:28:20.121765Z","iopub.status.idle":"2021-12-27T00:28:27.234874Z","shell.execute_reply.started":"2021-12-27T00:28:20.121729Z","shell.execute_reply":"2021-12-27T00:28:27.233661Z"},"trusted":true,"id":"rVS17rAkdqn3","executionInfo":{"status":"ok","timestamp":1681151978959,"user_tz":-330,"elapsed":4826,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Notebook "],"metadata":{"id":"AKNP5CqXdqn8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zh83Y6_vd2iy","executionInfo":{"status":"ok","timestamp":1681152005230,"user_tz":-330,"elapsed":23516,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}},"outputId":"0f507ac3-53f1-4690-a9de-9adcba551633"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### Codes are mainly from : [Partial Convolution Keras](https://github.com/MathiasGruber/PConv-Keras)\n","\n","\n","#### Purpose : \n","\n","#### 1. Testing some properties about texture & content synthesis for image inpainting task\n","\n","#### 2. This notebook trains 2 models to test the idea from [Instance Normalization: The Missing Ingredient for Fast Stylization](https://arxiv.org/abs/1607.08022)\n","\n","#### 3. And further do some experiment about difference between In and Bn, better understanding the idea from  [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) and [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155)"],"metadata":{"id":"6TbX3ZJSdqn9"}},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"Plg08WzGdqn9"}},{"cell_type":"markdown","source":["## Partial Convolution"],"metadata":{"id":"JsTIFEzCdqn-"}},{"cell_type":"code","source":["class PConv2D(tf.keras.layers.Conv2D):\n","    def __init__(self, *args, n_channels=3, mono=False, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.input_spec = [tf.keras.layers.InputSpec(ndim=4), tf.keras.layers.InputSpec(ndim=4)]\n","\n","    def build(self, input_shape):        \n","        \"\"\"Adapted from original _Conv() layer of Keras        \n","        param input_shape: list of dimensions for [img, mask]\n","        \"\"\"\n","        \n","        if self.data_format == 'channels_first':\n","            channel_axis = 1\n","        else:\n","            channel_axis = -1\n","            \n","        if input_shape[0][channel_axis] is None:\n","            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n","            \n","        self.input_dim = input_shape[0][channel_axis]\n","        \n","        # Image kernel\n","        kernel_shape = self.kernel_size + (self.input_dim, self.filters)\n","        self.kernel = self.add_weight(shape=kernel_shape,\n","                                      initializer=self.kernel_initializer,\n","                                      name='img_kernel',\n","                                      regularizer=self.kernel_regularizer,\n","                                      constraint=self.kernel_constraint)\n","        # Mask kernel\n","        self.kernel_mask = K.ones(shape=self.kernel_size + (self.input_dim, self.filters))\n","\n","        # Calculate padding size to achieve zero-padding\n","        self.pconv_padding = (\n","            (int((self.kernel_size[0]-1)/2), int((self.kernel_size[0]-1)/2)), \n","            (int((self.kernel_size[0]-1)/2), int((self.kernel_size[0]-1)/2)), \n","        )\n","\n","        # Window size - used for normalization\n","        self.window_size = self.kernel_size[0] * self.kernel_size[1]\n","        \n","        if self.use_bias:\n","            self.bias = self.add_weight(shape=(self.filters,),\n","                                        initializer=self.bias_initializer,\n","                                        name='bias',\n","                                        regularizer=self.bias_regularizer,\n","                                        constraint=self.bias_constraint)\n","        else:\n","            self.bias = None\n","        self.built = True\n","\n","    def call(self, inputs, mask=None):\n","\n","        # Padding done explicitly so that padding becomes part of the masked partial convolution\n","        images = K.spatial_2d_padding(inputs[0], self.pconv_padding, self.data_format)\n","        masks = K.spatial_2d_padding(inputs[1], self.pconv_padding, self.data_format)\n","\n","        # Apply convolutions to mask\n","        mask_output = K.conv2d(\n","            masks, self.kernel_mask, \n","            strides=self.strides,\n","            padding='valid',\n","            data_format=self.data_format,\n","            dilation_rate=self.dilation_rate\n","        )\n","\n","        # Apply convolutions to image\n","        img_output = K.conv2d(\n","            (images*masks), self.kernel, \n","            strides=self.strides,\n","            padding='valid',\n","            data_format=self.data_format,\n","            dilation_rate=self.dilation_rate\n","        )        \n","\n","        # Calculate the mask ratio on each pixel in the output mask\n","        mask_ratio = self.window_size / (mask_output + 1e-8)\n","\n","        # Clip output to be between 0 and 1\n","        mask_output = K.clip(mask_output, 0, 1)\n","\n","        # Remove ratio values where there are holes\n","        mask_ratio = mask_ratio * mask_output\n","\n","        # Normalize iamge output\n","        img_output = img_output * mask_ratio\n","\n","        # Apply bias only to the image (if chosen to do so)\n","        if self.use_bias:\n","            img_output = K.bias_add(\n","                img_output,\n","                self.bias,\n","                data_format=self.data_format)\n","        \n","        # Apply activations on the image\n","        if self.activation is not None:\n","            img_output = self.activation(img_output)\n","            \n","        return [img_output, mask_output]\n","    \n","    def compute_output_shape(self, input_shape):\n","        space = input_shape[0][1:-1]\n","        new_space = []\n","        for i in range(len(space)):\n","            new_dim = conv_utils.conv_output_length(\n","                space[i],\n","                self.kernel_size[i],\n","                padding='same',\n","                stride=self.strides[i],\n","                dilation=self.dilation_rate[i])\n","            new_space.append(new_dim)\n","        new_shape = (input_shape[0][0],) + tuple(new_space) + (self.filters,)\n","        return [new_shape, new_shape]"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:28:27.236758Z","iopub.execute_input":"2021-12-27T00:28:27.237115Z","iopub.status.idle":"2021-12-27T00:28:27.260525Z","shell.execute_reply.started":"2021-12-27T00:28:27.237078Z","shell.execute_reply":"2021-12-27T00:28:27.259465Z"},"trusted":true,"id":"vvt0veXVdqn-","executionInfo":{"status":"ok","timestamp":1681152024008,"user_tz":-330,"elapsed":538,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Instance Normalization"],"metadata":{"id":"SEdTbECAdqoA"}},{"cell_type":"code","source":["class InstanceNormalization(tf.keras.layers.Layer):\n","    def __init__(self, epsilon=1e-5):\n","        super(InstanceNormalization, self).__init__()\n","        self.epsilon = epsilon\n","        \n","    def build(self, input_shape):\n","        self.scale = self.add_weight(\n","            name='scale',\n","            shape=input_shape[-1:],\n","            initializer=tf.random_normal_initializer(1., 0.02),trainable=True)\n","\n","        self.offset = self.add_weight(\n","            name='offset',\n","            shape=input_shape[-1:],\n","            initializer='zeros',\n","            trainable=True)\n","        \n","    def call(self, x):\n","        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n","        inv = tf.math.rsqrt(variance + self.epsilon)\n","        normalized = (x - mean) * inv\n","        return self.scale * normalized + self.offset"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:28:27.262067Z","iopub.execute_input":"2021-12-27T00:28:27.262308Z","iopub.status.idle":"2021-12-27T00:28:27.289047Z","shell.execute_reply.started":"2021-12-27T00:28:27.262276Z","shell.execute_reply":"2021-12-27T00:28:27.288Z"},"trusted":true,"id":"jWff5nm4dqoA","executionInfo":{"status":"ok","timestamp":1681152035719,"user_tz":-330,"elapsed":449,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Generator UNET "],"metadata":{"id":"guea8dGBdqoB"}},{"cell_type":"code","source":["    def generator(norm_type='Bn',train=True):      \n","\n","        # INPUTS\n","        inputs_img = tf.keras.layers.Input((None, None, 3), name='inputs_img')\n","        inputs_mask = tf.keras.layers.Input((None, None, 3), name='inputs_mask')\n","        \n","        \n","        def encoder_layer(img_in, mask_in, filters, kernel_size,norm_type,norm=True):\n","            conv, mask = PConv2D(filters, kernel_size, strides=2, padding='same')([img_in, mask_in])\n","            if norm:\n","                if norm_type=='In':\n","                    conv=InstanceNormalization()(conv)\n","                else:\n","                    conv=tf.keras.layers.BatchNormalization()(conv,training=train)\n","                    \n","            conv = tf.keras.layers.ReLU()(conv)\n","            return conv, mask\n","\n","        \n","        e_conv1, e_mask1 = encoder_layer(inputs_img, inputs_mask, 64, 7, norm_type,norm=False)\n","        e_conv2, e_mask2 = encoder_layer(e_conv1, e_mask1, 128, 5,norm_type)\n","        e_conv3, e_mask3 = encoder_layer(e_conv2, e_mask2, 256, 5,norm_type)\n","        e_conv4, e_mask4 = encoder_layer(e_conv3, e_mask3, 512, 3,norm_type)\n","        e_conv5, e_mask5 = encoder_layer(e_conv4, e_mask4, 512, 3,norm_type)\n","        e_conv6, e_mask6 = encoder_layer(e_conv5, e_mask5, 512, 3,norm_type)\n","        e_conv7, e_mask7 = encoder_layer(e_conv6, e_mask6, 512, 3,norm_type)\n","        e_conv8, e_mask8 = encoder_layer(e_conv7, e_mask7, 512, 3,norm_type)\n","        \n","        \n","        def decoder_layer(img_in, mask_in, e_conv, e_mask, filters, kernel_size,norm_type, norm=True):\n","            up_img = tf.keras.layers.UpSampling2D(size=(2, 2))(img_in)\n","            up_mask = tf.keras.layers.UpSampling2D(size=(2, 2))(mask_in)\n","            concat_img = tf.keras.layers.Concatenate(axis=-1)([e_conv, up_img])\n","            concat_mask = tf.keras.layers.Concatenate(axis=-1)([e_mask, up_mask])\n","            \n","            conv, mask = PConv2D(filters, kernel_size, padding='same')([concat_img, concat_mask])\n","            \n","            if norm:\n","                if norm_type=='In':\n","                    conv=InstanceNormalization()(conv)\n","                else:\n","                    conv=tf.keras.layers.BatchNormalization()(conv,training=train)\n","            conv = tf.keras.layers.LeakyReLU(alpha=0.2)(conv)\n","            return conv, mask\n","            \n","        d_conv9, d_mask9 = decoder_layer(e_conv8, e_mask8, e_conv7, e_mask7, 512, 3,norm_type)\n","        d_conv10, d_mask10 = decoder_layer(d_conv9, d_mask9, e_conv6, e_mask6, 512, 3,norm_type)\n","        d_conv11, d_mask11 = decoder_layer(d_conv10, d_mask10, e_conv5, e_mask5, 512, 3,norm_type)\n","        d_conv12, d_mask12 = decoder_layer(d_conv11, d_mask11, e_conv4, e_mask4, 512, 3,norm_type)\n","        d_conv13, d_mask13 = decoder_layer(d_conv12, d_mask12, e_conv3, e_mask3, 256, 3,norm_type)\n","        d_conv14, d_mask14 = decoder_layer(d_conv13, d_mask13, e_conv2, e_mask2, 128, 3,norm_type)\n","        d_conv15, d_mask15 = decoder_layer(d_conv14, d_mask14, e_conv1, e_mask1, 64, 3,norm_type)\n","        d_conv16, d_mask16 = decoder_layer(d_conv15, d_mask15, inputs_img, inputs_mask, 3, 3, norm_type,norm=False)\n","        outputs = tf.keras.layers.Conv2D(3, 1, activation = 'sigmoid', name='outputs_img')(d_conv16)\n","        \n","        # Setup the model inputs / outputs\n","        model = tf.keras.Model(inputs=[inputs_img, inputs_mask], outputs=outputs)\n","\n","        return model"],"metadata":{"id":"O-7auWDFdqoB","executionInfo":{"status":"ok","timestamp":1681152040910,"user_tz":-330,"elapsed":6,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## VGG Extractor"],"metadata":{"id":"r6DjzcYadqoB"}},{"cell_type":"code","source":["def VGG():\n","\n","    #pool1, pool2 and pool3 for both perceptual loss & style loss\n","    \n","    vgg16=VGG16(include_top=False,weights=None)\n","    vgg16.load_weights('../input/vgg16-weights/pytorch_to_keras_vgg16.h5',by_name=True)\n","    vgg16.trainable=False\n","    \n","    layer_names=['block1_pool','block2_pool','block3_pool']\n","    \n","    outputs = [vgg16.get_layer(name).output for name in layer_names]\n","    \n","    return tf.keras.Model([vgg16.input], outputs)"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:44.501602Z","iopub.execute_input":"2021-12-27T00:29:44.502227Z","iopub.status.idle":"2021-12-27T00:29:44.508836Z","shell.execute_reply.started":"2021-12-27T00:29:44.502189Z","shell.execute_reply":"2021-12-27T00:29:44.507782Z"},"trusted":true,"id":"gzqWml6BdqoC","executionInfo":{"status":"ok","timestamp":1681152044549,"user_tz":-330,"elapsed":8,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"SCrmoJM7dqoC"}},{"cell_type":"markdown","source":["## Prepare Data"],"metadata":{"id":"iL-COpwrdqoC"}},{"cell_type":"code","source":["img_size=256\n","\n","batch_size=16\n","\n","lr=1e-4\n","\n","epochs=50\n","\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","fine_tune=True #fine tune\n","frozen_layers=[5,8,11,14,17,20,23]"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:44.93082Z","iopub.execute_input":"2021-12-27T00:29:44.931104Z","iopub.status.idle":"2021-12-27T00:29:44.935824Z","shell.execute_reply.started":"2021-12-27T00:29:44.931074Z","shell.execute_reply":"2021-12-27T00:29:44.934884Z"},"trusted":true,"id":"hNYIr3r7dqoD","executionInfo":{"status":"ok","timestamp":1681152058255,"user_tz":-330,"elapsed":661,"user":{"displayName":"James Mirajkar","userId":"14488204002484976852"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["pth='../input/imagenet/imagenet'\n","pth_mask='../input/inpainting-mask-generator/mask'\n","\n","#train\n","train_folder=sorted(os.listdir(f'{pth}/train'))\n","train_mask_folder=sorted(os.listdir(f'{pth_mask}/train'))\n","df_train=pd.DataFrame(np.vstack([train_folder,train_mask_folder]).T,columns=['pth','pth_mask'])\n","df_train['pth']=df_train['pth'].apply(lambda x: os.path.join(f'{pth}/train/{x}'))\n","df_train['pth_mask']=df_train['pth_mask'].apply(lambda x: os.path.join(f'{pth_mask}/train/{x}'))\n","\n","\n","#val\n","val_folder=sorted(os.listdir(f'{pth}/val'))\n","val_mask_folder=sorted(os.listdir(f'{pth_mask}/val'))\n","df_val=pd.DataFrame(np.vstack([val_folder,val_mask_folder]).T,columns=['pth','pth_mask'])\n","df_val['pth']=df_val['pth'].apply(lambda x: os.path.join(f'{pth}/val/{x}'))\n","df_val['pth_mask']=df_val['pth_mask'].apply(lambda x: os.path.join(f'{pth_mask}/val/{x}'))"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:45.060618Z","iopub.execute_input":"2021-12-27T00:29:45.06271Z","iopub.status.idle":"2021-12-27T00:29:46.312876Z","shell.execute_reply.started":"2021-12-27T00:29:45.062672Z","shell.execute_reply":"2021-12-27T00:29:46.311932Z"},"trusted":true,"id":"TmGBTZUydqoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_image(path,path_mask):\n","    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n","    image=tf.cast(tf.image.resize(image,(img_size,img_size)),'float32')\n","    image=image/255.\n","    \n","    mask = tf.image.decode_jpeg(tf.io.read_file(path_mask), channels=3)\n","    mask=tf.cast(tf.image.resize(mask,(img_size,img_size)),'float32')\n","    mask=mask/255.\n","    return image,mask"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:46.348962Z","iopub.execute_input":"2021-12-27T00:29:46.349233Z","iopub.status.idle":"2021-12-27T00:29:46.363467Z","shell.execute_reply.started":"2021-12-27T00:29:46.3492Z","shell.execute_reply":"2021-12-27T00:29:46.362654Z"},"trusted":true,"id":"LMqWMVK8dqoD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#all 0~255\n","ds_train=tf.data.Dataset.from_tensor_slices((df_train['pth'],df_train['pth_mask'])).map(get_image,num_parallel_calls=AUTOTUNE).\\\n","                        shuffle(256).batch(batch_size,drop_remainder=True)\n","\n","ds_val=tf.data.Dataset.from_tensor_slices((df_val['pth'],df_val['pth_mask'])).map(get_image,num_parallel_calls=AUTOTUNE).\\\n","                        batch(batch_size,drop_remainder=True)"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:46.365216Z","iopub.execute_input":"2021-12-27T00:29:46.365647Z","iopub.status.idle":"2021-12-27T00:29:46.518717Z","shell.execute_reply.started":"2021-12-27T00:29:46.36561Z","shell.execute_reply":"2021-12-27T00:29:46.517796Z"},"trusted":true,"id":"k35kignldqoE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Objective"],"metadata":{"id":"0kd1D9VXdqoE"}},{"cell_type":"code","source":["vgg=VGG()"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:46.519937Z","iopub.execute_input":"2021-12-27T00:29:46.520161Z","iopub.status.idle":"2021-12-27T00:29:52.83022Z","shell.execute_reply.started":"2021-12-27T00:29:46.520131Z","shell.execute_reply":"2021-12-27T00:29:52.829309Z"},"trusted":true,"id":"Ept0HtEMdqoE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def l1(y_true, y_pred):\n","    if K.ndim(y_true) == 4:\n","        return K.mean(K.abs(y_pred - y_true), axis=[1,2,3])\n","    elif K.ndim(y_true) == 3:\n","        return K.mean(K.abs(y_pred - y_true), axis=[1,2])\n","    \n","    \n","def gram_matrix(x):\n","    # Permute channels and get resulting shape\n","    x = tf.transpose(x, perm=(0, 3, 1, 2))\n","    shape = tf.shape(x)\n","    B, C, H, W = shape[0], shape[1], shape[2], shape[3]\n","        \n","    # Reshape x and do batch dot product\n","    features = tf.reshape(x, tf.stack([B, C, H*W]))\n","    gram = tf.keras.backend.batch_dot(features, features, axes=2)\n","        \n","    # Normalize with channels, height and width\n","    gram = gram /  tf.cast(C * H * W, x.dtype)\n","        \n","    return gram"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.832074Z","iopub.execute_input":"2021-12-27T00:29:52.832287Z","iopub.status.idle":"2021-12-27T00:29:52.842399Z","shell.execute_reply.started":"2021-12-27T00:29:52.832257Z","shell.execute_reply":"2021-12-27T00:29:52.841139Z"},"trusted":true,"id":"2wBDuPItdqoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def loss_hole(mask, y_true, y_pred):\n","    return l1((1-mask) * y_true, (1-mask) * y_pred)\n","    \n","def loss_valid(mask, y_true, y_pred):\n","    return l1(mask * y_true, mask * y_pred)\n","    \n","def loss_perceptual(vgg_out, vgg_gt, vgg_comp): \n","    loss = 0\n","    for o, c, g in zip(vgg_out, vgg_comp, vgg_gt):\n","        loss += l1(o, g) + l1(c, g)\n","    return loss\n","        \n","def loss_style(output, vgg_gt):\n","    loss = 0\n","    for o, g in zip(output, vgg_gt):\n","        loss += l1(gram_matrix(o), gram_matrix(g))\n","    return loss\n","\n","    \n","def loss_tv(mask, y_comp):\n","    kernel = tf.ones(shape=(3, 3, mask.shape[3], mask.shape[3]))\n","    dilated_mask = K.conv2d(1-mask, kernel, data_format='channels_last', padding='same')\n","\n","    dilated_mask = tf.cast(K.greater(dilated_mask, 0), 'float32')\n","    P = dilated_mask * y_comp\n","\n","    a = l1(P[:,1:,:,:], P[:,:-1,:,:])\n","    b = l1(P[:,:,1:,:], P[:,:,:-1,:])        \n","    return a+b"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.843757Z","iopub.execute_input":"2021-12-27T00:29:52.844002Z","iopub.status.idle":"2021-12-27T00:29:52.858609Z","shell.execute_reply.started":"2021-12-27T00:29:52.84397Z","shell.execute_reply":"2021-12-27T00:29:52.857499Z"},"trusted":true,"id":"VCxsuTCOdqoF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","def loss_func(y_true, y_pred, mask):\n","    y_comp = mask * y_true + (1-mask) * y_pred\n","    vgg_out = vgg((y_pred-mean)/std)\n","    vgg_gt = vgg((y_true-mean)/std)\n","    vgg_comp = vgg((y_comp-mean)/std)\n","            \n","    l1 = loss_valid(mask, y_true, y_pred)\n","    l2 = loss_hole(mask, y_true, y_pred)\n","    l3 = loss_perceptual(vgg_out, vgg_gt, vgg_comp)\n","    l4 = loss_style(vgg_out, vgg_gt)\n","    l5 = loss_style(vgg_comp, vgg_gt)\n","    l6 = loss_tv(mask, y_comp)\n","    \n","    return l1 + 6*l2 + 0.05*l3 + 120*(l4+l5) + 0.1*l6"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.86051Z","iopub.execute_input":"2021-12-27T00:29:52.861401Z","iopub.status.idle":"2021-12-27T00:29:52.875709Z","shell.execute_reply.started":"2021-12-27T00:29:52.861262Z","shell.execute_reply":"2021-12-27T00:29:52.874483Z"},"trusted":true,"id":"M3J45QapdqoF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train"],"metadata":{"id":"ExOLRVd4dqoF"}},{"cell_type":"code","source":["def show(x,mask,model,n=6):\n","    \n","    x_masked= x*mask+(1-mask)\n","    \n","    x_pred=model([x_masked,mask],training=False)\n","    \n","    mask = tf.concat([mask for _ in range(3)], -1)\n","    \n","    fig,ax=plt.subplots(nrows=3,ncols=n,figsize=(8,8))\n","    \n","    for i in range(3):\n","        for j in range(n):\n","            if i==1:\n","                x=x_masked\n","            elif i==2:\n","                x=x_pred\n","            ax[i,j].imshow(x[j])\n","    plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.8774Z","iopub.execute_input":"2021-12-27T00:29:52.877755Z","iopub.status.idle":"2021-12-27T00:29:52.890397Z","shell.execute_reply.started":"2021-12-27T00:29:52.877705Z","shell.execute_reply":"2021-12-27T00:29:52.889194Z"},"trusted":true,"id":"9HgBvFZEdqoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(x,mask,model,opt):\n","    with tf.GradientTape() as tape:\n","        x_masked= x*mask+(1-mask)\n","        \n","        x_prime=model([x,mask],training=True)\n","        \n","        loss=tf.reduce_mean(loss_func(x,x_prime,mask))\n","        \n","    grad=tape.gradient(loss,model.trainable_variables)\n","    opt.apply_gradients(zip(grad,model.trainable_variables))\n","    \n","    return loss"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.892018Z","iopub.execute_input":"2021-12-27T00:29:52.892337Z","iopub.status.idle":"2021-12-27T00:29:52.90242Z","shell.execute_reply.started":"2021-12-27T00:29:52.892292Z","shell.execute_reply":"2021-12-27T00:29:52.901411Z"},"trusted":true,"id":"VATai3WkdqoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","    try:\n","        G=tf.keras.models.load_model('../input/inpainting-models/model_bn/model_in')\n","        \n","        if fine_tune:\n","            for i in frozen_layers:\n","                G.layers[i].trainable=False\n","                lr=1e-5\n","    except:\n","        G=generator('In')\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=lr)\n","    ckpt = tf.train.Checkpoint(G=G,optimizer=optimizer)\n","    ckpt_manager = tf.train.CheckpointManager(ckpt,'./ckpt', max_to_keep=1)\n","    print('start training')\n","    for epoch in range(epochs):\n","        if epoch%5==0:\n","            print('sampling')\n","            for x,mask in ds_val:\n","                show(x,mask,G)\n","                break \n","                \n","            #save\n","            ckpt_manager.save()\n","            tf.keras.models.save_model(G,'./model')\n","            \n","        loop=tqdm(ds_train)\n","        for x,mask in loop:\n","            loss=train_step(x,mask,G,optimizer)\n","            loop.set_postfix(loss=f'loss:{loss}')\n","    return G"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.904273Z","iopub.execute_input":"2021-12-27T00:29:52.904568Z","iopub.status.idle":"2021-12-27T00:29:52.919664Z","shell.execute_reply.started":"2021-12-27T00:29:52.904537Z","shell.execute_reply":"2021-12-27T00:29:52.918704Z"},"trusted":true,"id":"IyXgYIE6dqoG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G=train()"],"metadata":{"execution":{"iopub.status.busy":"2021-12-27T00:29:52.921222Z","iopub.execute_input":"2021-12-27T00:29:52.921812Z"},"trusted":true,"id":"QdGVZcCmdqoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lU4OxI6JdqoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N9dniksQdqoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"djuOP158dqoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rI2z4rxodqoH"},"execution_count":null,"outputs":[]}]}